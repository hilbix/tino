> Der Text ist noch nicht fertig

# KI

KI ist in aller Munde.  (Würg)

## Wir haben verloren

Ich habe etwas über das Thema KI, Copyright und Patente nachgedacht ..
und meine, dabei ein "klitzekleines" Problem entdeckt zu haben.

Oder um es mal klarer auszudrücken, ein fatales Problem.  Nicht für KI.  Aber für Copyright und Patente.

Denn beides ist inkompatibel zur KI.

Damit meine ich nicht nur, dass eine KI kein Copyright und kein Patent erzeugen kann.
Sprich, dass alle Sachen, die die KI macht gemeinfrei sind.
Das ist nicht das eigentliche Problem, sondern nur die Ursache.

## Warum eine KI kein Copyright haben darf

Das dürfte eigentlich klar sein.  Eine KI ist ein Computeralgorithmus.
Ein Programm.  Ein Programm, das etwas erzeugt.

Nun ist eine KI erst einmal ein Programm.  Nämlich etwas, das aus einer Eingabe eine Ausgabe erzeugt.

Nun, das tun alle Programme.  Und an dem Output eines Programmes, wie z.B. FreeCAD oder Blender,
kann der Autor, also derjenige, der die Eingabe gemacht hat, sehr wohl ein Copyright haben.

Warum?  Weil die Kreativität beim Menschen liegt und der Rest ein rein deterministischer Vorgang ist.
Aus demselben Input bekommt man denselben Output.  So sind diese Programme gestaltet.

Aber genau hier weicht die KI ab.  Eine KI ist technisch nicht mehr zwingend deterministisch.

> Da eine KI in einer Von-Neumann-Maschine ausgeführt wird, ist ihr Vorgang grundsätzlich erst einmal
> Deterministisch.  Aber bei der KI kommen massiv Zufallsgeneratoren zum Einsatz.
> Diese können deterministisch, also vorhersagbar sein.  Müssen es aber nicht.
>
> Derzeit sind sie es meistens, weil wir ja nachvollziehbare Ergebnisse haben wollen.
> Aber genau das ist nicht notwendig und kann nicht garantiert werden.
> Außerdem kann eine KI auf defekter Hardware Rechenfehler vollziehen,
> was dann weiterin sinnvolle aber nicht mehr determinstische Ergebnisse liefern kann.

Das Problem ist einfacher gesagt die Nachvollziehbarkeit.

Es ist vollkommen nachvollziehbar, wie das Ergebnis eines Computerprogramms zustande gekommen ist.
Bei der KI aber ist die Komplexität so hoch, dass wir zur Nachvollziehbarkeit eines einzigen Ergebnisses
mehr Zeit brauchen werden, als in diesem Universum zur Verfügung steht.  Damit ist die Nachvollziehbarkeit
nicht mehr gegeben.

## Wo ist da der Unterschied zur Kreativität?

Genau.  Wo ist der Unterschied?  Ich kann keinen erkennen.

Kreativität ist der Ausdruck einer von anderen Menschen erkennbaren, aber nicht nachvollziehbaren Eigenschaft.

Genau das tun die KIs nun auch.  Scheiße.  Damit haben wir die Wahl:

Entweder stellen wir die KI also auf dieselbe Stufe wie Menschen.
Oder wir tun das nicht.

Letzteres dürfte besser sein.  Sonst .. nun ja, wollen wir, dass techische Dinge wie KIs
dieselben Rechte wie lebendige Menschen haben?

Also ich denke, die Zeit ist dafür noch nicht dafür reif.  Oder anders gesagt:

## Die KI als Sklave der Menschheit

Die KI wurde von uns erschaffen und trainiert genau zu diesem Zweck, das zu tun, was wir von ihr wollen.
Nicht mehr und nicht weniger.  Die KI selbst hat keine Rechte.  Und für sie verantwortlich ist der Mensch,
der sie hergestellt hat bzw. überwachen muss.

> Bei selbstfahrenden Autos ist das somit der Hersteller, weil dies der Betreiber des Autos selbst nicht mehr kann.
>
> Wie soll ich als Insasse eines selbstfahrenden Autos auch binnen Sekundenbruchteilen eingreifen können,
> wenn ich dafür nicht einmal mehr die erforderlichen Bedienelemente habe?

Das mag sich in Zukunft vielleicht ändern, denn als nächster Schritt bin ich mir ziemlich sicher,
dass KI und Menschen verschmelzen werden.  Sprich, wir können dann nicht mehr sagen,
wo fängt die KI an oder wo hört der Mensch auf.  Der Übergang wird derart fließend werden,
dass wir irgendwann nicht einmal mehr Androiden und Cyborgs auseinanderhalten können werden.

> Ghost in the Shell.  Sprich, die Frage wird dann sein, hat die Maschine (noch) einen Ghost,
> oder nicht.  Ich denke nicht, dass das in Zukunft noch von einem biologischen Gehirn abhängig gemacht werden kann.
>
> Insbesondere wenn Quantenchips mit in diese Gleichung einfließen ist der Unterschied zwischen
> dem biologischen Gehirn (dessen Nervenzellen auf Quantenebene arbeiten) und einem maschinellen
> Prozess, in dem Quanteneffekte eine Rolle spielen, nicht mehr wirklich erkenn- und definierbar.

Aber das ist die Zukunft.  Machen wir uns deshalb heute keine Gedanken darum,
das müssen die zukünftigen Generationen für sich entscheiden.

Wichtig ist nur, was bedeutet die KI heute für uns?  Welche Konsequenzen müssen wir aus dem ziehen,
was wir heute schon und in absehbarer Zukunft noch machen können.

Und die KI hat gerade so etwas wie einen Quantensprung gemacht, bzw. macht ihn gerade.
Sie ist von einer theoretischen Wissenschaft zu einem praktikabel anwendbaren generalisierten Modell geworden.

KI war schon vorher in vielen Bereichen aktiv.
Aber das waren ganz konkrete Verfahren, die für einen ganz konkreten Ansatz entwickelt wurden.

Das, was wir gerade erleben, ist aber der generalisierte Ansatz.  Also wie die KI aus einer speziellen Anwendbarkeit
zu einem generalisierten Tool wird, welches auf alle möglichen Dinge angewendet werden kann.

> Selbstfahrende Autos gehören dabei zu dem alten Ansatz.  Denn diese Autos werden auf die Situationen
> trainiert und werden weiterhin absolut deterministisch arbeiten.  Sprich, über die Black Box werden
> wir exakt den Input der KI nachvollziehen können, und damit auch den Output der KI verstehen können.
>
> Selbstfahrende Autos profitieren allerdings von der neuen Entwicklung in diesem Sinn, dass wir die Hardware der KI,
> die am Ende das Auto steuert, günstiger konstruieren und die Software überhaupt entwickeln sowie updaten können.
>
> Aber letzteres, also den Prozess der Erzeugung der KI die das Auto steuert, den werden wir nicht mehr
> nachvollziehen können!  Denn dies wird ein fließender Prozess sein, viel zu komplex um ihn noch
> "deterministisch" (also nachvollziehbar) in obiger Weise zu nennen - denn niemand wird ihn jemals
> in der Zeit vollständig nachvollziehen und verstehen können, in der das auf den Markt kommt.
> Vermutlich werden das nicht einmal die KIs selbst.
>
> Aber die Verfahren werden ausführlichst getestet werden.  Und bei Unfällen - die es immer geben wird -
> wird der Prozess dann ständig verbessert und optimiert werden, bis es sehr unwahrscheinlich wird,
> dass es überhaupt noch zu einem Unfall kommen kann.
>
> Ich gehe davon aus, dass wir dann in der Presse von solchen Unfällen lesen werden.  Es wird dann
> seltener sein als Vorfälle in Kernkraftwerken, und in etwa so häufig wie Naturkatastrophen,
> die nichts mit dem Wetter zu tun haben (wie Vulkanausbrüche oder Asteroideneinschläge).

## Und genau hier ist das Problem

Die KIs verselbständigen sich gerade.  Nicht in dem sinne von Skynet und Weltuntergang.
Sondern im Sinne von ubiquitärem Einsatz und Alltäglichkeit.

Es wird nicht mehr lange dauern, und wir haben deutlich mehr KIs auf dem Planten als Menschen.
Jedes Smartphone enthält inzwischen schon mehrere davon.  Und auch im Auto werkeln sie schon heute.
In so Sachen wie ABS und ASP.

Das sind zwar sehr primitive KIs und eigentlich nur noch Algorithmen, die wir (weitgehend) nachvollziehen können.
Aber letzteres ändert sich gerade.  Die Algorithmen werden so komplex, dass wir sie eben nicht mehr genau
nachvollziehen können.  Wenn sich die Dynamik das Fahrwerks selbständig auf die Straßenbeschaffenheit
einstellt, und dabei nicht nur externe Wetterdaten und Geoinformationen (Straßenführung die kommt)
sondern die aktuelle Fahrsituation einfließt, und außerdem hunderte von Sensoren gleichzeitig Daten
einfließen lassen (wie z.B. vom Antikollisionsradar uvm.), dann ist das am Ende nicht mehr nachvollziehbar.
Nur noch optimierbar.  Aber nicht mehr nachvollziehbar.

> Deshalb brauchen wir die Black-Box in Autos, die alle Daten bei Unfällen aufzeichnen und zur Auswertung bringen.
> Nur so können wir die Dinge noch weiter optimieren.
>
> Ein einziger besonderer Unfall wird vielleicht noch weitgehend nachvollzogen werden können.
> Aber wir wollen ja besser sein.  Also werden mehr Unfälle in die Daten einfließen als wir nachvollziehen können
> bzw. vorher nachvollzogen haben.  Und genau da haben wir dann plötzlich nicht mehr die Datenhoheit.
> 
> Und es werden KI-Algorithmen sein, die uns dabei helfen, die Daten zu sichten und für das Training und die
> Kontrolle der Ergebnisse bereitstellen.  Anders ist das überhaupt nicht mehr möglich.

Wenn also die KIs in alles und jedes einfließen, und das werden sie, wie sieht es dann mit dem Copyright aus?

Das Copyright bzw. Patente sind dafür da, den kreativen Prozess bzw. die Erfindung zu schützen.
Wenn jeman Jahre mit Forschung verbracht hat und dann zu einer Lösung kam, dann muss das belohnt werden.

Aber wie steht es damit, wenn Myriaden an KIs binnen Sekundenbruchteilen zu einem gleichen oder ähnlichen Ergebnis kommen?
Wo ist da die Erfindungshöhe, der kreative Prozess?  Ist das schützenswert?

Sicher nicht!

Was schützenswert ist, wäre vielleicht die KI selbst, die das vollbringen kann.

Aber das ändert an dem Problem nichts.  Das Programm ist geschützt.  Der Output eines Programms ist es aber nicht!
Wäre ja noch schöner, wenn der Hersteller eines Programms (z.B. Microsoft) dann am Output eines Programms
(Word) plötzlich alle Rechte hätte.  Oder der Druckerhersteller am Brief den ich ausdrucke.

> Technisch gesehen ist jeder Ausdruck heutzutage ein Unikat.  Jedenfalls auf Farbdruckern.
> Diese kodieren nicht nur ihre Seriennummer sondern auch weitere Metadaten in den Ausdruck.
> So kann man also nachvollziehen, wer was wann wo wie und in welcher Reihenfolge ausgedruckt hat.
>
> Also wenn ich gar nicht mehr bestimmen kann was ausgedruckt wird, wer besitzt daran also die Rechte?
> Bisher ist das soweit klar:  Ich.
>
> (Bei so Dingen wie der Flugblattaffaire haben wir aber gesehen, ganz so einfach ist es nicht.)
>
> Aber bei KIs, die dann den Brief für mich geschrieben hat, halt nimmer.
> Dann ist nur noch klar, wer dafür verantwortlich ist:
> Ich, der den Brief losschickt.
> (Spätestens seit der Flugblattaffaire wissen wir, dass das bereits heute schon nicht so ist.)
>
> Aber das wird in Zukunft eben im Normalfall nicht mehr zu bestimmen sein:
> Ich, der das selbstfahrende Auto losschickt.  Ohne dass ich drinnen sitze!

Wenn der Input der Programme nicht von einem Menschen stammt oder gewählt wurde,
außerdem ubuquitär von hunderten oder mehr KIs parallel erzeugt werden kann,
und am Output der Programme niemand implizit irgendwelche Rechte bekommt,
dann ist der Output selbst nicht mehr schützenswert.

So weit so klar.

Wenn ich also eine KI verwende um etwas zu erzeugen, an dem ich selbst gar keinen Anteil mehr habe,
dann ist das Ergebnis somit gemeinfrei.


## Warum das Ergebnis einer KI gemeinfrei sein muss

Mal abgesehen davon dass es heute schon aus logischer Herleitung so sein muss,
könnten wir ja hergehen, und das rechtlich ändern.

Stellen wir uns also vor, der Output der KI wäre schützenswert.

Wer hat denn dann die Rechte am Output?

Na, logischerweise so wie bei Fotografen.  Jemand fotografiert einen Blitz in den Wolken.
Und am Bild hat er dann alle Rechte.

- Nicht der Softwarehersteller, der die KI programmiert hat, die die Bildoptimierung machte.
- Nicht der Hersteller des Photosensors, der per KI optimiert wird, um optimal auf jede Lichtsituation eingestellt zu sein.
- Nicht der Designer, der die Kamera per KI optimiert hat, damit sie optimale Bedienführung und Nutzung bietet.
- Nicht der Kamerahersteller, dessen KI das optimale Bild aus der impliziten Reihe der Bilder auswählt, ohne dass der Fotograf überhaupt weiß, dass da so ein Ding für ihn arbeitet.

Also, ändern wir das!  Ändern wir die Rechte am Output!

In genau diesem Beispiel haben wir dann plötzlich statt des Fotografen gleich 4 weitere Entitäten,
die Ansprüche am Output anmelden können:

- Ohne die KI vom Kamerahersteller wäre der Blitz nicht vollständig erwischt worden.  Das kann man nachweisen.
- Ohne die KI vom Designer hätte der Fotograf die Kamera nicht genausogut in Stellung bringen können.  Das ist nachweisbar.
- Ohne die KI vom Sensor wäre das Bild durch den Blitz überstrahlt, die Wolken wären nicht sichtbar und der ganze Eindruck vom Bild dahin.  Das ist absolut sicher.
- Ohne die KI vom Softwarehersteller der Bildkompression wären die feinen Details vom Bild total verwaschen.  Auch das ist bekannt.

Was war jetzt eigentlich nochmals die Leistung vom Fotografen?

Zum richtigen Zeitpunkt die Kamera in die richtige Richtung zu halten und den Rest haben die KIs seiner Kamera erledigt?
Also alles nur reiner Zufall?

Ja, das ist bereits so!  Einige Handys lösen schon aus, bevor man auf den Auslöser drückt!  Weil sie ständig aufnehmen
und dann aus der Zeit, in der wir auf den Auslöser drücken, so ungefähr das richtige Bild rauskramen.

Das geht gar nicht anders, weil die "Auslösung" zu "Bild jetzt aufnehmen" einfach Zeit braucht.
Bei meinen alten Handys waren das teils mehrere Sekunden!  (Leider kein Witz!)
Inzwischen ist das aber instant.  Teils sogar mehr als instant.  Das Bild wird schon aufgenommen,
bevor die eigentliche Software dafür vollständig geladen werden konnte.  Dank moderner Technik im Sensor!

> Einige Handyhersteller werben sogar mit dem Feature.

Also, wer nimmt hier eigentlich noch das Bild auf?  Ich?  Sicher nicht.
Ich sage nur, wann ich etwas festgehalten haben möchte.  Den Rest erledigt das Handy für mich.

Wenn wir also anfangen, den KIs Rechte am Output zu geben, öffenen wir die Büchse der Pandora.

Können wir also das Dilemma, dass KI generierter Output gemeinfrei ist, ändern?

Ja, das können wir.

Dürfen wir das ändern?

Auf keinen Fall!  Sonst verlieren nicht nur Fotografen die Rechte am Bild!

> Ich gehe hier nicht darauf ein, dass viele KIs derzeit noch mit nicht-gemeinfreien Daten trainiert wurden
> und so lebende Künstler nachahmen können.
>
> Das können Fälscher nämlich auch und teils sogar besser als KIs.  In wiefern der Stil eines Künstlers
> geschützt ist, das überlasse ich anderen zu beurteilen.
>
> Ich gehe davon aus, dass das ein reines Übergangsproblem ist.  Zukünftige KIs werden gemeinfrei und allgemein
> trainiert.  Und dann reicht es, dass man ihr ein einziges Bild eines Künstlers zeigt,
> damit diese nicht nur in einem ähnlichen Stil Bilder herstellen kann, sondern sogar eine perfekte Replik.
>
> Also vom Bild eines Ölgemäldes das Ölgemälde.  Inklusive Herstellung der Farben und Leinwand per atomarem 3D-Druck,
> so dass alles perfekt in die Zeit vom Künstler passt.
> Und so, davon gehe ich aus, werden wahrscheinlich alternde Kunstwerke in Zukunft auch restauriert.
>
> Die Frage ist nicht, ob wir das tun können.  Die Frage ist nur, wie lange dauert es, bis es wirtschaftlicher wird,
> als einen Restaurateur dafür zu anzustellen.  Wenn das nicht schon in diesem Jahrhundert passiert,
> dann ganz sicher in diesem Jahrtausend!


## Na und?

Wir haben also festgestellt, dass der Output der KI selbst gemeinfrei ist.

Aber das Beispiel vom Fotograf zeigt ja, dass das - mal von der KI abgesehen - kein Problem darstellt.

Wenn es denn so einfach wäre!

Das Beispiel des Fotografen ist noch recht einfach.  Die KI ist nur ein reines Hilfsmittel.
Die KI ist ja an dem Vorgang selbst nur mittelbar beteiligt.

Aber genau das ändert sich jetzt.  Stellen wir uns vor, der Fotograf bedient die Kamera nicht.

Er stellt ein Stativ auf, montiert eine 2-Achs-Steuerung darauf, und auf diese die Kamera.

Eine KI bewegt jetzt die Kamera in die interessante Richtung und löst sie bei interessanten Bildern aus.
So wie eine Webcam, nur eben vollautomatisch.

Nun montiert man das Stativ auf ein selbstfahrendes Auto.  Und die KI steuert auch noch, wohin das Auto fährt.

Der Fotograf baut einen Service, über den man der KI sagen kann, was man gerne fotografiert hätte,
und dann dann über den Service die dadurch entstandenen Fotos herunterladen.

> Ob dafür bezahlt werden muss oder nicht ist für die Betrachung vollkommen irrelevant.

Wer hat an den Bildern jetzt die Rechte?

- Der, der Fotograf?  Weil er das Ding gebaut hat und sich Fotograf schimpft?
- Der, der die KI über das Web beauftragt hat?
- Der, der die Bilder heruntergeladen (und ggf. dafür bezahlt) hat?

Und was, wenn dann rauskommt, dass es das Auto mit der Kamera gar nicht gibt und alles nur ein Hoax war,
die Bilder vollständig von einer KI erzeugt wurden, die diese aus passenden Motiven aus vorhandenen
Webcam-Streams zusammengeschustert hat?

Denn genau das ist die Situation, auf die wir zusteuern.

- Texte von KI generiert.
- Bilder von KI generiert.
- Bisher als krativ angesehene Verfahren von KI gesteuert und die Ergebnisse entsprechend erzeugt.

usw.  Während aber der Tassenhersteller noch das Geschmacksmuster für sich beanspruchen kann,
wenn jemand ein Fake-Produkt dieser Tasse auf den Markt bringt,
steht dem bei der KI die Gemeinfreiheit des Outputs der KI im Weg.

Wenn also jemand mit der Hilfe von KI eine Tasse designet,
hat er dann noch daran die Rechte?

Darf er daran überhaupt die Rechte besitzen, wenn jeader andere dies ebensogut kann,
wenn er dieselbe KI verwendet?

Ich würde sagen:

Nur dann, wenn der Hersteller auch die KI selbst vollständig hergestellt und betrieben hat.
Die KI, als Teil des gesamten Vorgangs, also vollstingig ausschließlich im Besitz des Herstellers ist.

Aber genau das wird in Zukunft eben genau so nicht sein.  Denn schon heute kann man eine KI eigentlich
nicht mehr selbst trainieren.  Man nimmt vortrainierte Modelle und passt das auf den eigenen Vorgang an.
Damit besitzt man nicht mehr die vollständigen Rechte an der KI.

Das ist ebenso der Fall, wenn man die Inputs der KI nicht vollständig besitzt.


## Erste Voraussetzung

Wenn ich die Rechte am Output einer KI vollständig besitzen will, dann ist also ein entscheidender Punkt der,
ob jemand dasselbe tun kann wie ich.

Wenn das nicht gegeben ist (beispiel Fotograf, Blitz und KI baiserte Kamera),
also niemand es mir gleich machen kann, dann ist das der Fall.

Wenn jemand es aber nachmachen kann (also einen ähnlichen Blitz fotografieren),
dann kann ich dem anderen das Recht nicht verwehren.

Wenn es jeder nachmachen kann (dank KI), bedeutet das, ich habe keinerlei Rechte mehr,
die ich durchsetzen kann.

Diese Betrachung ist aber zu einfach und reicht nicht mehr aus.


## Zweite Voraussetzung

Die zweite Voraussetzung kommt ins Spiel, wenn die KI einen wesentlichen Anteil am Output hat.

Bei Kameras und Handys, die das Bild nur optimeren, ist es wohl noch meistens nicht der Fall,
dass die KI daran einen wesentlichen Anteil hat.

Bei KI generierten Texten und Bildern aber ist das etwas vollkommen anderes.
Hier hat die KI nicht nur wesentlichen sondern sogar ursächlichen Anteil am Ergebnis.

Das aber führt nicht zwangsläufig dazu, dass man am Output keine Rechte haben kann.

Sofern man die KI vollständig selbst trainiert hat, mit eigenem Input an dem man alle Rechte hat,
und die KI nicht an Dritte weitergegeben hat, dann besitzt man (IANAL, aber ich würde sagen,
das ist vollkommen logisch) auch weiterhin alle Rechte am Output.

Das sind aber gleich eine ganze Reihe von wichtigen Faktoren:

- Es muss sich um ein ungelerntes, also nicht vortrainiertes Modell handeln.
- Dort dürfen nur eigene Inputs einfließen an denen man exklusiv alle Rechte innehat
- Das Training muss zwingend inhouse passieren, so dass niemand sonst einen Anteil hat
- Und das Modell darf ausschließlich inhous ablaufen

Die Cloud schließt sich hier aus.  Warum?  Weil man nicht ausschließen kann,
dass dadurch Effekte entstehen, die ggf. anderen Rechte einräumen können.

> WTF?  Ist leider so.  Während Spectre und Co. bei anderen Prozessen keine Rolle spielen,
> sondern unerwünschte Fehler darstellen, sind Spectre und Co. in rechtlicher Hinsicht leider viral.

Es ist nun einmal so, dass das Urheberrecht auch für einbrechende Schmierfinken gilt.
Wenn also ein Einbrecher eine Schmiererei veranstaltet, ist das einerseits Sachbeschädigung,
andererseits aber bleibt er rechtlich der Urheber am Grafitti, und dieses Recht kann man ihm nicht entziehen.

Durch Spectre kann es also passieren, dass jemand - evtl. sogar unabsichtlich - rechtlich beteiligt ist,
weil ihm die Informationen während des Vorgangs offengelegt wurden.
Ob er dies nun wahrnimmt oder nicht ist vollkommen egal.  Urheber bleibt Urheber.

Dies lässt sich nur vermeiden, indem man beim Training keine Cloud nutzt.

Außerdem würde ich hier die Sache noch deutlich enger ziehen.  Die KI darf deshalb nicht in die Cloud,
weil sie sonst veröffentlicht wird.  Sprich, derjenige, der die Cloud betreibt, bekommt somit
ebenfalls in besitz der KI, kann diese also ausführen.

Plötzlich hat man also nicht nur einen, der die KI betreiben kann, sondern viele.
Nämlich prinzipiell alle in der Cloud.

Durch Fehler wie Spectre und Co. können diese ggf. sogar unberechtigt an den Code der KI kommen.

Man kann sich die Sache nun einfach machen und sagen, das läuft halt wie bei Trade-Secrets.
Sprich, wer meinen Code unberechtigt verwendet, gegen den kann ich rechtlich vorgehen.

Ganz so einfach ist die Sache aber nicht.

> Denken wir an den Schmierfinken.  Hypothetischer Fall:
>
> Der bekannte Grafittikünstler X beschmiert die Motorhaube eines 2 Mio$ Ferraris ohne Kenntnis des Autobesitzers.
> Der Autobesitzer lässt die Motorhaube überlackieren und verlangt Schadensersatz vom Grafittikünstler.
> Im Gegenzug verlangt der Grafittikünstler die Herausgabe seines Werkes, also der Motorhaube.
> Da die Motorhaube nicht mehr existiert (überlackiert), verlangt der Künstler nun Schadesnersatz vom Autobesitzer.
>
> Am Ende bekomt der Grafittikünstler 5 Mio EUR vom Autobesitzer.  Warum?
> Weil sein "Kunstwerk" mehr wert war als das Auto und der Autobesitzer das Kunstwerk leider zerstört hat.
>
> Der Autobesitzer muss die 5 Mio EUR bezahlen, kann den Wagen aber für 10 Mio EUR an einen Fan vom Künstler
> verkaufen, als das "Zerstörte Kunstwerk vom Grafittikünstler X" und hat so nach Abzug der Anwaltkosten
> noch 3 Mio EUR übrig um sich einen neuen Ferrari zu kaufen.

Was ist, wenn jemand die KI nicht direkt klaut, sondern nur beobachtet, und daraus seine eigene KI baut,
die dann die originale immitieren kann.  Das ist nicht abwegig sondern inzwischen möglich.
Denn genau so funktionieren KIs ja.  Sie werden anhand von Beobachtungen trainiert.

Hat man den Code einer KI, dann kann man anhand dieser eine vollkommen neue KI trainieren.
Das ist viel einfacher als eine KI durch Dinge wie Spectre zu beobachten,
aber das Ergebnis ist weitgehend dasselbe.

> Denken wir an vortrainierte KIs, die in der Lage sein werden, einen Stil eines Künstlers nachzuahmen,
> indem man ihr nur ein (einziges!) Bild zeigt und sagt "mach so etwas ähnliches".

Ich kann also

- eine neue KI bauen, die wie die originale KI funktioniert
- oder die bestehende KI zusätzlich trainieren, so dass sich ihr Modell ändert
- oder ggf. auch eine vollkommen neue KI trainiert haben die zufällig so funktioniert wie die andere

Welcher der 3 Fälle vorliegt, den kann ich letzendlich nicht entscheiden.
Und weil ich das nicht kann, muss ich Vorkehrungen treffen.

Die ersten zwei Fälle kann ich ausschließen, indem ich die KI bei mir streng unter Verschluss halte.
Dass der lettze Fall passiert ist dann eher unwahrscheinlich, aber nicht ausgeschlossen.

Wenn der letztere Fall auftritt, kann ich nichts dagegen machen.

> Siehe Beispiel Fotograf und Blitzfoto.

