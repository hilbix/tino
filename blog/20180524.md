# sv3 und sv4

- Problem: Rechner hat selbsttätig rebootet
- Ursache: Stromausfall im RZ, Fehlerhafte USV
- Dauer: 11:00-19:10 (sv4) 11:00-09:00 (sv3)

Betroffene (wichtigere) VMs:

- Meine Homepage
- susi
- ts
- libepo Backend

Grund der Downtime:

- Die Maschine kommt nach einem Reboot von selbst hoch.
- sv4: Das ZFS-Filesystem muss derzeit manuell aktiviert werden.
  - Nachdem ZFS aktiviert ist müssen die VMs angefahren werden.
- sv3: Das ZFS-Filesystem kommt zwar von selbst hoch, aber der Webservice startet vor ZFS und fällt dadurch auf die Nase

Ich sollte das irgendwie automatisieren.

- Alle Probleme inkl. Probleme mit den VMs, siehe "Issues".

Das Gute im Schlechten:  Beide Hosts haben nun aktuelle Kernel, d. h. Meltdown-Fixes sind auch auf den Hosts aktiv.


## Protokoll

`/var/log/messages`:
```
May 24 08:51:11 sv4 rsyslogd-2007: action 'action 19' suspended, next retry is Thu May 24 08:51:41 2018 [try http://www.rsyslog.com/e/2007 ]
May 24 12:10:55 sv4 rsyslogd: [origin software="rsyslogd" swVersion="8.4.2" x-pid="3469" x-info="http://www.rsyslog.com"] start
May 24 12:10:55 sv4 kernel: [    0.000000] CPU0 microcode updated early to revision 0x22, date = 2017-01-27
```

`/var/log/syslog`:
```
May 24 11:03:01 sv4 CRON[5663]: (root) CMD (bin/minute.sh)
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@May 24 12:10:55 sv4 rsyslogd: [origin software="rsyslogd" swVersion="8.4.2" x-pid="3469
" x-info="http://www.rsyslog.com"] start
```

`kern.log`:
```
May 24 08:55:25 sv4 kernel: [20001759.269479] UDP: bad checksum. From 60.191.0.242:58433 to 144.76.115.105:1080 ulen 49
May 24 12:10:55 sv4 kernel: [    0.000000] CPU0 microcode updated early to revision 0x22, date = 2017-01-27
```

`auth.log`:
```
May 24 11:03:10 sv4 CRON[5662]: pam_unix(cron:session): session closed for user root
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
May 24 12:10:56 sv4 sshd[4122]: Server listening on 0.0.0.0 port 22.
```

Sieht nach einem spontanen Reset aus.

## Issues

## sv4

- Kam selbständig hoch, aktivierte aber ZFS nicht.
- Aktionen dafür siehe `/root/README`

### VM susi.de

- Die Uhrzeit stimmt nicht.  Sie war 2h off.  Behauptet MESZ zu sein, ist aber UTC.  Aktion:
  - In `/etc/sysconfig/clock` eingetragen `HWCLOCK="-u"`, mal sehen ob das dann in Zukunft passt.
- NTP läuft, es hätte sich also von selbst gesynct, irgendwann, aber so ist das besser.

## sv3

- Kam vollständig hoch, aktivierte auch ZFS, aber nicht den Webservice.
- Diesen habe ich manuell durchgestartet (siehe `/root/README`), dann war alles OK

## Ursache

Die Ursache fand sich auf https://www.hetzner-status.de/

```
Störungsmeldung Stromversorgung/Netzwerk Datacenterpark Falkenstein 		
Typ: 	Störungsmeldung 	
Kategorien: 	Basis Infrastruktur
Start: 	24. Mai 2018 11:30:00 CEST
Ende: 	Unbekannt
Beschreibung: 	Aufgrund einer aktuellen Störung der Stromversorgung am Standort Falkenstein, gibt es derzeit Erreichbarkeitsprobleme einiger Kundenserver. Unsere Techniker arbeiten aktuell an der Ursachenanalyse und wir werden Sie entsprechend auf dem Laufenden halten.
Update: 	24. Mai 2018 12:10:00 CEST 	
	Update: Nach aktueller Kenntnislage gab es gegen 11:00 Uhr im DC7, DC10 + DC12 einen Stromausfall. Durch den einhergehenden Ausfall von Core-Netzwerktechnik am Standort Falkenstein, gab es durch die Spannungsunterbrechung einen kurzzeitgen Ausfall des gesamten Netzwerks im Datacenterpark Falkenstein
Update: 	24. Mai 2018 12:27:00 CEST 	
	Zwischenzeitlich konnte die Stromversorgung in den drei betroffenen Rechenzentren provisorisch (ohne USV-Absicherung) wiederhergestellt werden.

Ursache für den Ausfall war eine starke Spannungsabsenkung im örtlichen Stromnetz. Warum es trotz USV-Absicherung zu Ausfällen gekommen ist, wird noch geprüft. Aktuell hat die Wiederherstellung des gesicherten Betriebs oberste Priorität.

Unsere Techniker sind gerade dabei zu ermitteln, wie viele Server manuell nach der Unterbrechung geprüft werden müssen.

Update: 	24. Mai 2018 14:28:00 CEST 	
	Zwischenzeitlich ist die USV-Schiene wieder im FSN1-DC10 wieder aktiv und es konnte die USV-Absicherung in Teibereichen(einigen Subverteilern) von DC10 wiederhergestellt werden.

Wir arbeiten weiterhin mit Hochdruck an der Wiederherstellung des gesicherten Regelbetriebes.
Update: 	24. Mai 2018 16:36:00 CEST 	
	Zwischenzeitlich wurden alle Server die nicht automatisch nach dem Spannungsabfall wieder angelaufen sind eingeschaltet bzw. auf defekte Netzteile geprüft. Im nächsten Schritt wird dazu übergegangen, die Tickets in den betroffenen Rechenzentren zu bearbeiten - Server die aktuell nicht erreichbar sind, müssen alle individuell geprüft werden, da die Fehlerbilder hier sehr unterschiedlich ausfallen.

Derzeit befinden sich folgende Tickets in den Queues:

DC 07 1013
DC 10 1408
DC 12 465

Um die Bearbeitung nicht weiter zu verzögern bitten wir Sie, lediglich ein Ticket pro betroffenen Server zu erstellen.

Vielen Dank.
Update: 	24. Mai 2018 18:29:00 CEST 	
	Die Analyse der durch die starke Spannungsabsenkung im örtlichen Stromnetz betroffenen und zum Teil beschädigten USV-Anlagen(Modulen)/Subverteilern läuft weiterhin mit Hochdruck.

Zum Teil können betroffene und defekte USV-Module/Subverteiler mit vorhandenen Ersatzteilen durch Techniker des USV-Anlagenherstellers repariert werden, andere Ersatzteile befinden sich im Zulauf und wir arbeiten weiterhin mit Hochdruck an der Wiederherstellung des gesicherten Regelbetriebes. Genauere Informationen wann der gesicherte Regelbetrieb in den betroffen Rechenzentren 7/10/12 wieder hergestellt sein wird, wird sich vermutlich erst morgen abzeichen. Bis dahin befinden sich die betroffenen Rechenzentren ohne oder nur in Teibereichen(einigen Subverteilern) in USV-Absicherung.

Vielen Dank für Ihr Verständnis.
```
