> Von https://www.heise.de/forum/heise-online/Kommentare/IT-Sicherheit-Wenn-KI-gegen-KI-kaempft/Und-was-hat-das-jetzt-bitte-mit-KI-zu-tun/posting-39077445/show/

Und was hat das jetzt bitte mit KI zu tun?

KI hin, KI her,  
KI Marketingebrabbel das lieb ich sehr.  
KI steht drauf und ist auch drin,  
So des Maketingfuzzies liebst Gesinn.

Und wenn sie nicht gestorben sind,  
dann wird demnächst noch jedes Kind  
gar glauben die Mär von der KI,  
aber wahr, das wird sie nie!

Marketinggeschwurbel glaubt besser nicht,  
denn das, was ihr vom Einkauf kriegt,  
das wird nicht einmal ansatzweise  
das tun was schrieb da Heise.

Als Dichter bin ich nicht daheim,  
so geht's nun weiter ohne Reim.

Sorry, aber was ich da lesen muss ist IMHO kompletter Unsinn. Dumpfes Marketinggeschwurbel, und offensichtlich viele Leute, die voll darauf hereingefallen sind.

https://www.theverge.com/2016/10/10/13224930/ai-deep-learning-limitations-drawbacks

Nicht die KI greift an. Jemand greift mit der Unterstützung von KI an.
So weit, dass die KI angreift, sind wir noch lange nicht.

Deshalb kämpft da auch nicht die KI mit der KI.
Umhergottshimmelswillen, wer verdammt noch eins, keine Seite will das!
Und ganz sicher lasse ich niemals eine KI auf meine IT los.

Das ist alles keine KI. Denn KI bedeutet, die KI lernt.

https://de.wikipedia.org/wiki/K%C3%BCnstliche_Intelligenz

Die Fähigkeit zu lernen ist eine Hauptanforderung an KI-Systeme und muss ein integraler Bestandteil sein, der nicht erst nachträglich hinzugefügt werden darf.

Genau das tut sie aber hier nicht und das will man auch nicht.

Also was machen wir stattdessen?

Wir saugen uns eine Menge Daten, lassen die auf die KI los damit sie die als "Normal" klassifiziert, und dann schalten wir das Lernen ab und lassen die KI nur noch die weiter einfließenden Indikatoren aussortieren.

Warum machen wir das? Weil sonst nur Stuss rauskommt.

Wenn die KI ständig lernt können wir nämlich gar nichts mehr erreichen,
denn die KI weiß ja nicht, was "normal" ist und was nicht.

Wenn also jemand in das Netz eindringt und nur behutsam genug vorgeht,
dann würde die KI das als "normal" erlernen. Und wenn man dann wieder
langsam vorgeht und Daten abzieht, würde auch das die KI als "normal"
lernen. Erst dann, wenn der Angriff vorüber ist, würde die KI Alarm schlagen.
Warum? Na, das Netz ist jetzt "anormal", da ja keine Daten mehr abfließen ..

So, guckt mal nach. Welche Angriffe waren in den letzten Jahren besonders erfolgreich? Die mit der Brechstange, oder die, die reingesneakt sind?

Soviel also zum Thema "KI zur Abwehr". Stuß in, Stuß ouch.

Eine KI zu haben die hinterher Alarm schlägt klingt für mich nicht gerade vernünftig.
Wir wollen ja VORHER Alarm schlagen, nicht hinterher. Also müssen wir das selbstlernen abschalten. Bei der Verteidigung, jedenfalls.

Umgekehrt wird aber ein Schuh draus. Der Angreifer will ja, dass seine KI das
angegriffene System kennenlernt. Also wird er es angreifen und dessen Reaktion
aufzeichnen. Die KI sagt dann vorher, wie das angegriffene System reagieren wird.

So kann ich das System angreifen ohne das System selbst anzugreifen. (Upps!)

Preisfrage: Wenn ein Hacker an ein System moderate (unterhalb des Rauschens) unverdächtige Probes schickt, und dann sein daraus trainiertes KI-System anzugreifen
um herauszufinden, welche Vektoren bei dem angeprobeten System evtl. Erfolg versprechen, wieviel von diesen Angriffen sieht die abwehrende KI?

Genau: Gar nix außer den seltenen Probes. Das triggert da deshalb auch überhaupt keinen Alarm.

Wenn dann der, dank KI, geplante Angriff kommt, kommt der auch nicht von der KI.
Sondern vom Menschen, der den Vektor, den er mit der KI ermittelt hat, einsetzt,
um - sehr behutsam - in das System einzudringen. Was kriegt die ach-so-tolle
verteidigende KI davon mit? Nix! Läuft voll unter dem Radar.
(Deshalb gab es ja die KI beim Hacker, die davor schützt, dass das verteidigende IDS Alarm schlägt.)

So sieht ein KI-Angriff aus. Und auch die Verteidigung oder genauer deren Abwesenheit.
(Ich spreche von heute, nicht von in 10 Jahren. Was da sein wird weiß niemand heute schon.
Wenn ihr es nicht glaubt, beantwortet mal folgende Frage: Hat sich da IPv6 durchgesetzt? Ja? Nein? Ich sage mal: Egal worauf Du setzt, es wird sich als "mehr falsch" erweisen als richtig!)

Ja, mit KI kann man die Verteidigung (gegen bekannte "dumme" Attacken) trainieren. Aber das Training ist nichts, was vor-Ort läuft, denn da habe ich ja nicht die notwendigen Attacken parat. (Die Variante der lernenden - nicht: selbstlernenden - KI vor-Ort um "Normal" zu erkennen, die aber dann anschließend im "nichtlerndenen" Modus läuft, also dann nimmer KI ist sondern nur noch ein analysierendes System, die hatten wir ja schon oben abgehandelt.)

Das ist so wie mit den selbstfahrenden Autos. Ja, die Erkennung von Gefahren, das Ausweichen usw., das ist alles inzwischen per KI trainiert. In millionen, wenn nicht abermilliarden simulierten Varianten. Aber im Auto selbst läuft anschließend kein Stück KI! (Wenn Tesla etwas anderes mitteilt, dann lügen sie. Warum? Teslas wären sonst nicht auf deutschen Straßen zugelassen. Kommt mir nicht mit dem Shadow-Mode. Wäre das kein Hoax, wäre es höchst unsinnig, einer KI beizubringen, wie der Mensch fährt. Ein schlechteres Vorbild kann man nicht finden, jedenfalls nicht in unserem zugänglichen Universum. Punkt!)

Und warum ist das so?

Versicherungen! Eine Versicherung will im Fall des Unfalls den Hergang ermitteln können. Ist da eine willkürlich handelnde KI beteiligt wird da niemals irgendetwas ermittelt werden können, da kommt nämlich dann nur Stuss bei raus. (Jedenfalls beim derzeitigen Stand der KI-Forschung.)

Genau deshalb gibt es keine KI in Fahrzeugen. Ja, es gibt aus der KI entstandene vorprogrammierte neuronale Netze, die aber selbst nichts lernen, sondern bis hin
zu der notwendigen garantierten Fehlertoleranz vorprogrammiert sind. Das ist
nicht KI, das ist so gesehen einfach nur eine hochkomplizierte mathematische Abbildung. Ein absolut deterministisches System, das aus klardefinierten Eingangsdaten klardefiniert Ausgangsdaten erzeugt. Ein System, das man zu 100% im Griff hat. Das absolut reproduzierbar und damit vorhersagbar reagiert. So dass man es, im Fall eines Unfalls, exakt nachvollziehen kann, wie es dazu kam.

Das einzige, was man eben NICHT beisteuert, das sind die realen Eingangsdaten im Betrieb. Aber dank Blackbox haben wir die ja bei jedem Unfall dann und können, sollten Trainingsdefekte vorhanden sein, die KI nachtrainieren. Nein, nicht die im Auto - da ist ja keine -, sondern die Systeme, aus deren Simulatoren dann die Fahrzeugelektronik ihre (fest definierte) Firmware bezieht.

Noch irgendwelche Fragen warum die Fahrzeuge, die selbstfahren werden, eine Blackbox brauchen? Warum es ohne nicht geht? Deshalb! Wäre da irgendwo KI, könnte man ja die KI befragen. So wie man heute den Fahrer befragt. Da ist aber eben genau keine KI weil wir das noch nicht können. Deshalb braucht es auch eine Blackbox.

Also:

Während der Angreifer tatsächlich KI einsetzen kann (ein selbstlernendes System, das vorhersagt, wie das angegriffene System reagiert) kann man das beim angegriffenen System eben genau gar nicht.

Aber dann kämpft immer noch nicht KI gegen KI, sondern Intellekt (bzw. dessen Fehlen auf Seiten der Konzerne) gegen Intellekt.

Oder anders gesagt:

SIE haben schon verloren, wollen es aber nicht wahr haben. Und deshalb fallen SIE, wieder und immer wieder, auf irgendwelche Marketingfuzzis herein, insbesondere wenn da so tolle Worte wie KI verwendet werden (das S in KI steht für Sinn und das Z in KI steht für Zweck).

Guckt auf Kaspersky.

Wie haben die - schon mehrfach - Angriffe gefunden? Durch KI?

Ja, aber eben nicht durch vor-Ort-KI, sondern durch KI erzeugte vor-Ort laufende Analysen, die Anomalien entdecken. Wie immer wird da die KI aus der Masse trainiert. Nicht die Masse an einer Stelle, sondern die Gesamtmasse aller. Und aus dieser Unmenge an Daten in der Cloud filtert man dann - in diesem Fall tatsächlich mit Hilfe von KI, die aber mehr auf Statistik basiert als auf echter KI, außerdem eben im Nachgang und nicht proaktiv - evtl. interessante Anomalien heraus, auf die mal ein Mensch gucken soll. Und nicht selten wird man so dann auch fündig. Wäre ja auch Unsinn eine Technik nicht zu nutzen wenn sie funktioniert.

Aber daran ist weder vor-Ort eine KI beteiligt noch eine beim Angriff. Die KI ist nur ein Tool. Klar kann ich sagen, dass der Hammer den Angriff geführt hat und dass das Schild den Angriff abwehrte. Aber beide Tools werden noch immer von Menschen geführt. Ja, noch.

Aber das wird lange genug gültig sein, so dass man jeden, der behauptet, man könne mit KI-Technik Geld und vor allem geschultes Personal sparen, eindeutig ein Scharlatan ist. Genau das Gegenteil ist der Fall:

Man kann sich nur das billige Personal sparen. Durch Reinungungsroboter wird das billige Reinigungspersonal überflüssig, aber nicht der Reinigungsexperte, der die Reinigungsmittel einkauft. Und man braucht nun jemanden, der den Reinigungsroboter wartet. Und überwacht. Sonst "reinigt" der Roboter am Ende die Leindwand vom vanGogh.

Auch anderweitig ist das Cool: Während man vorher, also zur Zeit vom Reinigungspersonal, noch persönlich vor-Ort gehen musste, um die Firma zu infiltrieren, reicht jetzt, den Bundestrojaner auf dem Saugroboter anzusprechen. Von egal woher. Man muss nicht einmal mehr die Wohnung verlassen oder sich selbst anstrengen um irgendwo einzubrechen. Und fürs Hacking sorgt der Staat.

Ganz von selbst und alles hübsch modern!

-Tino
PS: Nein, ich sage nicht, dass es hoffnungslos ist. Man muss nur einfach Leute dranlassen, die sich damit auskennen. Beispielsweise Cloudflare. Die haben das Personal um generelle Angriffe abzuwehren. Generelle welche, und das en-masse. Dafür brauche ich also keine KI bei mir, dafür gibt es externe Dienstleister (ich werte mal nicht, ob das gut oder schlecht ist, also ob Cloudflare Fluch oder Segen ist). Bei maßgeschneiderten Attacken (das sind die, die in Zukunft mit KI vorbereitet werden, aber eben keine KI beteiligt ist) sind derartige Dienstleister aber genauso nutzlos wie anderes IDS-Gedöhns. Dagegen hilft nur Resilienz sowie ein Schalendesign mit erzwungenen Medienbrüchen. Dazu eben noch Personal, das das System kennt und Anomalien intuitiv bemerkt. Aber wie immer: Gier schlägt Hirn. War schon immer so. Wird immer so sein. Die Ursuppe der Menschheit. Aber vielleicht (ich sage nur: vielleicht) kann uns die KI aus dieser menschlichen Fatalität retten. Denn auch der Mensch kann dem grundlegendsten aller Naturgesetze nicht entkommen: Faulheit schlägt einfach alles. (Damit auch die Gier.)

PPS: Und natürlich habe ich auch gelogen, schließlich bin ich auch nur ein Mensch. Und die größte menschliche Fähigkeit ist ja bekanntlich, sich selbst zu belügen. In vielen modernen Auto gibt es selbstredend eine KI. Zwar nur die von der Sprachsteuerung, die tatsächlich lernt, nämlich eure Stimme (so gut übrigens, dass man die mit deren Hilfe eure Stimme dann imitieren kann), aber immerhin, da lernt was!
